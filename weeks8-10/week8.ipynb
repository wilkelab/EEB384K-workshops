{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6759f2",
   "metadata": {},
   "source": [
    "# Week 8 Workshop\n",
    "\n",
    "In this week we are working with the protein language model ESM-2. The model family is available on HuggingFace: https://huggingface.co/facebook/esm2_t12_35M_UR50D\n",
    "\n",
    "We can access and use the model easily using the `transformers` library: https://huggingface.co/docs/transformers/en/index\n",
    "\n",
    "As always, we begin by importing the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b1ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import plotnine as pln\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer, EsmForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5306a87",
   "metadata": {},
   "source": [
    "Next we're loading the tokenizer and model.\n",
    "\n",
    "**Note:** If the following code runs extremely slowly or errors out you may have to update your python installation. Alternatively, you can try to run it in a python console, not in Jupyter. Older versions of Jupyter have a bug that prevents this code from running correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25b402",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "model = EsmForMaskedLM.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9abfc1",
   "metadata": {},
   "source": [
    "## Exploring the β-lactamase dataset\n",
    "\n",
    "We will be working with a deep mutational scanning dataset of the protein β-lactamase. The data comes from:\n",
    "\n",
    "> Stiffler MA, Hekstra DR, Ranganathan R (2015). Evolvability as a function of purifying selection in TEM-1 β-lactamase. Cell 160:882-892. https://doi.org/10.1016/j.cell.2015.01.035\n",
    "\n",
    "First we read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = pl.read_csv('./data/B-Lactamase_Ranganathan2015.csv')\n",
    "data_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba363075",
   "metadata": {},
   "source": [
    "Let's look at the distribution of the `target` value, which represents the fitness of each mutant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "density_plot = (\n",
    "    pln.ggplot(data_complete, pln.aes(x='target'))\n",
    "    + pln.geom_density()\n",
    "    + pln.theme_bw()\n",
    "    )\n",
    "density_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5e200",
   "metadata": {},
   "source": [
    "The distribution is bi-modal. Let's say the enzyme has high activity for fitness values above -1 and low activity otherwise. We'll add an activity column to the data to express this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88500161",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_complete.with_columns(\n",
    "    pl.when(pl.col('target') > -1)\n",
    "      .then(pl.lit('high'))\n",
    "      .otherwise(pl.lit('low'))\n",
    "      .alias('activity')\n",
    ")\n",
    "data_complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734d674f",
   "metadata": {},
   "source": [
    "Next we randomly down-sample to speed up the subsequent calculations. Set the fraction to 1 to work with the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52667be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fract = 0.1 # set to 1 to work with the complete dataset\n",
    "data = data_complete.sample(fraction = target_fract, seed=8592153)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713625e1",
   "metadata": {},
   "source": [
    "Let's see how many high and low activity mutants we have in the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d84d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5194997",
   "metadata": {},
   "source": [
    "The data set is roughly balanced. We don't have to worry about class imbalances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaeb540",
   "metadata": {},
   "source": [
    "## Predicting mutant activity\n",
    "\n",
    "We want to fit a classifier to distinguish between high activity and low activity mutants. To do this, we will first calculate embeddings, then do a PCA to reduce the embedding space, and then fit a logistic regression to the dimension-reduced embedding space. (We don't have enough data points to fit to the full space.)\n",
    "\n",
    "First we calculate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2befb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_representations = {}\n",
    "with torch.no_grad():  # disable gradient calculations\n",
    "    for seq_id, sequence in tqdm( # iterate using a nice progress bar\n",
    "        data.select(['ID', 'sequence']).iter_rows(), \n",
    "        desc = \"Processing sequences\", \n",
    "        leave = False,\n",
    "        total = len(data)\n",
    "    ):\n",
    "        # tokenize without padding or truncation\n",
    "        tokens = tokenizer(sequence, return_tensors = \"pt\", padding = False, truncation = False)\n",
    "        tokens = tokens.to(device)\n",
    "        \n",
    "        # get model output (hidden states are the embedding layers)\n",
    "        output = model(tokens['input_ids'], output_hidden_states = True)\n",
    " \n",
    "        # get the last hidden state\n",
    "        # (Not the most efficient for larger datasets. For larger we should use batches.)\n",
    "        embeddings = output.hidden_states[-1][0]  # Last layer, first and only sequence (batch size = 1)\n",
    "\n",
    "        # extract the mean embeddings for the sequence, excluding [CLS] and [EOS]\n",
    "        representations = embeddings[1:-1, :].detach().cpu()  \n",
    "        \n",
    "        # compute mean representation of the sequence\n",
    "        mean_representations[seq_id] = representations.mean(dim=0)\n",
    "\n",
    "# join emeddings and original data frame\n",
    "embed = pl.DataFrame(mean_representations).transpose(include_header=True, header_name='ID')\n",
    "embed_df = data.join(embed, on='ID')\n",
    "embed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f661dd6",
   "metadata": {},
   "source": [
    "Next we do a PCA and visualize active and inactive mutants in PC space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e348df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the embedding columns (there are 480 for the 35M parameter model)\n",
    "features = embed_df.select(pl.col([f'column_{str(i)}' for i in range(480)]))\n",
    "\n",
    "# run PCA and extract 20 components\n",
    "n_components = 20\n",
    "X_pca  = PCA(n_components=n_components).fit_transform(features)\n",
    "\n",
    "# create data frame of first two components for visualization\n",
    "pca_df = pl.DataFrame({\n",
    "    'PC1': X_pca[:, 0],\n",
    "    'PC2': X_pca[:, 1],\n",
    "    'Activity': embed_df['activity']\n",
    "})\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_plot = (\n",
    "    pln.ggplot(pca_df, pln.aes(x='PC1', y='PC2', color='Activity'))\n",
    "    + pln.geom_point(size=1.5, alpha=.7)\n",
    "    + pln.theme_bw()\n",
    ")\n",
    "pca_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf96391",
   "metadata": {},
   "source": [
    "There seems to be some separation between high and low activity mutants. Let's see if a logistic regression on 20 PC dimensions can successfully classify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0361accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create a numeric response variable\n",
    "# 0 = 'low', 1 = 'high'\n",
    "y = embed_df['activity'].replace({'low': 0, 'high': 1})\n",
    "\n",
    "# now we create the training/test split\n",
    "random_state = 16492345 # change for different train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size = 0.2, random_state = random_state, stratify = y\n",
    ")\n",
    "    \n",
    "print(f\"\\nTraining samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Feature dimension for classification: {X_train.shape[1]}\")\n",
    "    \n",
    "# train logistic regression classifier on PCA components\n",
    "print(f\"\\nTraining classifier on {n_components} principal components...\")\n",
    "clf = LogisticRegression(max_iter = 1000)\n",
    "clf.fit(X_train, y_train)\n",
    "    \n",
    "# make predictions\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "# evaluate performance\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"CLASSIFICATION RESULTS (using PCA components)\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")\n",
    "   \n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, \n",
    "                            target_names = ['low', 'high']))\n",
    "    \n",
    "print(\"Test Set Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"                  Predicted\")\n",
    "print(f\"               low        high\")\n",
    "print(f\"Actual low     {cm[0,0]:3d}        {cm[0,1]:3d}\")\n",
    "print(f\"       high    {cm[1,0]:3d}        {cm[1,1]:3d}\")\n",
    "    \n",
    "# create confusion matrix visualization\n",
    "cm_df = pl.DataFrame({\n",
    "    'actual': ['low', 'low', 'high', 'high'],\n",
    "    'predicted': ['low', 'high', 'low', 'high'],\n",
    "    'count': [cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]]\n",
    "})\n",
    "    \n",
    "cm_plot = (\n",
    "    pln.ggplot(cm_df, pln.aes(x = 'predicted', y = 'actual', fill = 'count'))\n",
    "    + pln.geom_tile(color = 'white', size = 1.5)\n",
    "    + pln.geom_text(pln.aes(label = 'count'), size = 20, color = 'white')\n",
    "    + pln.scale_fill_gradient(low = '#3498db', high = '#e74c3c')\n",
    "    + pln.scale_x_discrete(limits = ['high', 'low'])\n",
    "    + pln.scale_y_discrete(limits = ['low', 'high'])\n",
    "    + pln.labs(\n",
    "        x='Predicted',\n",
    "        y='Actual',\n",
    "        fill='Count'\n",
    "    )\n",
    "    + pln.theme_minimal()\n",
    ")\n",
    "\n",
    "cm_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695445b6",
   "metadata": {},
   "source": [
    "## Excercises\n",
    "\n",
    "- Use more of the data than just 10% and see how this changes results\n",
    "- Change the number of components in the PCA before classification\n",
    "- Use a different random seed in the training/test split\n",
    "- Use embeddings from different layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
